\section{Hilbert spaces}
\begin{defn}
  \textbf{Hilbert space} --- complete, infinite dimensional, inner product space.
\end{defn}

\begin{ex}
  $L_2(E)$ --- Hilbert space. \\
  $\inprod{f, g} = \int\limits_E f \cdot g\ d\mu$ \\
  $l_2 = \Set{(x_1, \dotsc, x_n, \dotsc) | \sum\limits_{n = 1}^\infty x_n^2 < +\infty}$ \\
  $\inprod{\bar{x}, \bar{y}} = \sum\limits_{n = 1}^\infty x_n y_n,\ E = \N,\ \mu\{m\} = 1$
\end{ex}

\noindent
When we have completeness we can define orthonormal basis.

\begin{defn}
  $H,\ \{e_n\}$ --- ONS $\colon \forall x = \sum\limits_{n = 1}^\infty \alpha_n e_n$
  Then $\{e_n\}$ is called \textbf{orthonormal basis}.\\
  Let's look at the inner product of arbitrary vector $x \in H$ and basis
  vector $e_m$ \\ 
  $\inprod{x, e_m} = \sum\limits_{n = 1}^\infty \alpha_n \inprod{e_n, e_m} =
  \alpha_m$ \\
  In this sense basis decomposition is always a Fourier series.
\end{defn}

\begin{enumerate}
\item Complete ONS\@: Let $L = \L\{e_1, e_2, \dots\}$, then $H = \cl{L}$ ($L$ is dense in $H$)
\item Closed ONS\@: $\forall m\ \inprod{x, e_m} = 0 \implies x = 0$.
\end{enumerate}

\begin{stm}
\label{stm:ons_properties} In Hilbert spaces two of the properties outlined above are equivalent.
\end{stm}

% \noindent
% $\sum\limits_{n = 1}^\infty y_n$ in $H$ --- orthogonal series. \\
% Because $H$ is a Hilbert space, it is also a complete space, thus convergence of
% the partial sums sequence $\lim\limits_{n, m \to +\infty} S_n - S_m = 0$ \\
% is equivalent to the fact that it is a Cauchy sequence: $\|S_n - S_m\| \to 0$ \\
% $S_n - S_m = \sum\limits_{k = n + 1}^m y_k \\
% \|S_n - S_m\|^2 = \left\langle \sum\limits_{i=n+1}^m y_i, \sum\limits_{j=n+1}^m
%   y_j \right\rangle = \sum\limits_{i, j = n+1}^m \langle y_i, y_j\rangle =
% \sum\limits_{j=n+1}^m \langle y_j, y_j \rangle = \sum\limits_{j=n+1}^m \|y_j\|^2 \\
% \|S_n - S_m\| \to 0 \iff \sum\limits_n^m \|y_k\| \to 0$ \\
% in $H\ \sum\limits_1^\infty \|y_k\|^2 < + \infty$ TODO: разобраться, что тут происходит
% ONS $x \mapsto \sum\limits_{k = 1}^\infty \inprod{x, l_k} l_k$ \\
% $\sum\limits_{k = 1}^\infty \inprod{x, l_k}^2 \leq \|x\|^2 < +\infty$

\begin{stm}
  In Hilbert space Fourier series converges for any point.
\end{stm}

\begin{proof}
  Let $H$ --- Hilbert space, $\sum\limits_{j = 1}^\infty \inprod{x, e_j}e_j$ --- abstract Fourier
  series, $S_n = \sum\limits_{j = 1}^n \inprod{x, e_j}e_j$ --- it's partial sum.
  We need to prove, that $\exists \lim\limits_{n \to \infty} S_n$.
  $H$ is a Hilbert space, which means it is also complete. This means we only
  have to prove that $\{S_n\}$ is Cauchy sequence, i.e. $\forall \epsilon > 0\
  \exists N \in \N \colon \forall n, m > N\ \|S_n - S_m\| < \epsilon$ \\
  Consider $\|S_n - S_m\|^2 = \norm{\sum\limits_{j = 1}^n \inprod{x, e_j} e_j -
    \sum\limits_{j =  1}^m \inprod{x, e_j}e_j}^2 = \norm{\sum\limits_{j = m +
      1}^n \inprod{x, e_j}e_j}^2 = \sum\limits_{j = m + 1}^n \abs{\inprod{x,
      e_j}}^2$ \\
  Because numerical series $\sum\limits_{j = m + 1}^n \abs{\inprod{x, e_j}}^2$
  converges, by the Cauchy criteria we have the following: $\forall \epsilon > 0
  \ \exists N \in \N\colon \forall n > m > N\ \abs{\sum\limits_{j = m + 1}^n
    \abs{\inprod{x, e_j}}^2} < \epsilon^2$ or $\sum\limits_{j = m + 1}^n
    \abs{\inprod{x, e_j}}^2 < \epsilon^2$, finally we get $\|S_n - S_m\| < \epsilon$.
\end{proof}

\begin{proof}
\ref{stm:ons_properties}
  Complete ONS $\implies$ Closed ONS \\
  $\forall x \in H\ \forall \epsilon > 0\ \exists \sum\limits_{j =
    1}^p \alpha_{kj}l_{kj}\colon \underbrace{\|x - \sum\limits_{j = 1}^p
    \alpha_{kj}l_{kj}\|^2}_{\geq \|x - \sum\limits_{j = 1}^{k_p} \inprod{x, l_j} l_j\|^2}
  \leq \epsilon^2$ \\
  $S_m(x)$ by extremety $\|x - S_{m + p}(x)\|^2 \leq \|x - S_m(x)\|^2$ \\
  Implies partial sums go to x, $x = \sum\limits_{j = 1}^\infty \inprod{x, l_j} l_j$
  If all fourier coefficients are zero, it means the ONS is closed $(x = 0)$. \\
  Closed ONS $\implies$ Complete ONS\\
  $y \in H = \sum\limits_{j = 1}^\infty \underbrace{\inprod{x, e_j}}_{ = \inprod{y,
      e_j}} e_j \implies \inprod{y, e_j} = \inprod{x, e_j} \implies \inprod{y - x,
    e_j} = 0$ \\
  Because ONS is closed $y - x = 0,\ y = x$. Thus we can decompose any point into
  Fourier series, and this implies that ONS is complete.
\end{proof}

Considering basis existance.
\begin{defn}
  Topological space is called \textbf{separable} if there exists countable dense set in it. \\
  $X = \cl{\{a_1, \dotsc, a_n, \dotsc\}}$
\end{defn}

$H$ --- separable, $a_1, \dotsc, a_n, \dotsc$ We can orthogonalize these dots
(Gramm-Shmidt), and we will get complete ONS.
This means space separability is equivalent to basis existance.
\begin{thm}[about best approximation in $H$]
  $H$ --- HS, $M$ --- closed convex subset of $H$, then $\forall x \in H \ \exists!
  y \in M \colon \|x -y\| = \inf\limits_{z \in M}\|x - z\|$.
  $M$ has element of best approximation for any $x$ from $X$, and only one.
\end{thm}

\begin{proof}
  $d = \inf\limits_{z \in M}\|x - z\|$ by definition of infimum \\
  $\forall n \in \N \ \exists y_n \in M \colon d \leq \|x - y_n\| < d + \dfrac 1n$ \\
  $\exists ? y = \lim y_n \in M\ d \leq \|x - y\| \leq d$ \\
  $y_n, y_m \in M$ --- convex. Implies
  \[
    \dfrac{y_n + y_m}{2} \in M \implies d^2
    \leq \norm{\dfrac{y_n + y_m}{2} - x}^2 = \dfrac{1}{4}\norm{\underbrace{(y_n - x)}_{z_1}
    + \underbrace{(y_m - x)}_{z_2}}^2 
  \]
\\ Let's use parallelogram law. $\|z_1 + z_2\|^2 + \|z_1 - z_2\|^2 = 2\|z_1\|^2
+ 2\|z_2\|^2$, \\
$\underbrace{\|(y_n - x) + (y_m - x)\|^2}_{\geq 4d^2} + \|y_n -
y_m\|^2 = 2\overbrace{\|y_n - x\|^2}^{\leq \left(d + \frac 1n\right)^2}
+ 2 \overbrace{\|y_m - x\|^2}^{\leq \left(d + \frac 1m\right)^2}$ \\
$\|y_n - y_m\|^2 \leq 2(d + \dfrac 1n)^2 + 2(d + \dfrac 1m)^2 - 4d^2 = 4d \dfrac
1n + \dfrac{2}{n^2} + 4 d \dfrac 1m + \dfrac{2}{m^2} \xrightarrow[n, m \to
  0]{} 0$ \\
$\|y_n - y_m\| \xrightarrow[n, m \to 0]{} 0 \implies \exists \lim y_n$
\end{proof}

\begin{cor}
  $H$ --- HS, $H_1$ --- subspace (closed linear subset). \\
  $H_2$ = $H_1^{\perp} = \Set{y \in H | y \perp x, x \in H_1}$ --- \textbf{orthogonal addition}. \\
  $\forall x \in H$ can be unambiguously written as $x = x_1 + x _2,\ x_1 \in H_1,\ x_2 \in H_1^{\perp}$
\end{cor}

\begin{note}
  $H = H_1 \oplus H_1^{\perp}$
\end{note}

\begin{proof}
  $x \in H,\ H_1,\ H_2 = H_1^{\perp} \\
  \exists x_1 \in H_1 \colon \|x - x_1\| = \inf\limits_{n \in H_1}\|x - n\| \\
  x_2 = x - x_1\ \in H_2 ? \\
  \forall y \in H_1 y \perp x_2,\ \lambda > 0,\ x_ 1+ \lambda y \in H_1 (H_1
  \text{--- subspace})$

  \noindent
  By definition of best approximation element
  $\|x - (x_1 - \lambda^2)\| \geq \|x - x_1\|^2 \quad \forall \lambda > 0 \\$
  Let's expand squared norms via inner product. \\
  $\langle\underbrace{x - x_1}_{x_2} - \lambda y, x - x_1 - \lambda y\rangle \geq
  \inprod{x - x_1, x - x_1} \\
   \inprod{x_2 - \lambda y, x_2 - \lambda y} \geq \inprod{x_2, x_2} \\
   \inprod{x_2, x_2} - 2 \lambda \inprod{y, x_2} + \lambda^2 \inprod{y, y} \geq
   \inprod{x_2, x_2}\ : \lambda > 0 \\
   2 \inprod{y, x_2} \leq \lambda \inprod{y, y},\ \lambda \to +0 \implies
   \inprod{y, x_2} \leq 0 \\$ 
   Substitute $y$ for $-y$:
   $\inprod{-y, x_2} \leq 0 \implies \inprod{y, x_2} \geq 0 \implies \inprod{y, x_2} = 0$
\end{proof}
