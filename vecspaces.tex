\chapter{Vector spaces.}
\section{Metric spaces.}

X, $\rho\colon X \times X \to \R_+$
\begin{defn}$\rho$ --- \textbf{metric}
  \begin{enumerate}
    \item $\rho(x, y) \geq 0, = 0 \iff x = y$
    \item $\rho(x, y) = \rho (y, x)$
    \item $\rho(x, y) \leq \rho (x, z) + \rho (y, z)$
  \end{enumerate}
\end{defn}
\begin{defn}$(X, \rho)$ --- \textbf{Metric space}.\end{defn}
\begin{defn}$x = \lim x_{n} \iff \rho(x_{n}, x) \to 0$\end{defn}
$X, \tau = \Set{G \subset X}$
\begin{defn}
  Let $X$ be arbitrary set. Then system of its subsets $\tau$ is called a
  \textbf{topology} if $\colon$
  \begin{enumerate}
  \item $\varnothing, X \in \tau$
  \item $G_\alpha \in \tau, \alpha \in \mathscr{A} \implies
    \bigcup\limits_\alpha G_\alpha \in \tau$
  \item $G_1, \dotsc, G_n \in \tau \implies \bigcap\limits_{j = 1}^n G_j \in
    \tau$
  \end{enumerate}
And any set $G \in \tau$ is called \textbf{open}.
\end{defn}

\begin{defn}$(X, \tau)$ --- \textbf{Topological space}.\end{defn}
$x = \lim x_n \quad \forall G \in \tau: x \in G \quad \exists N: \forall n > N \quad x_n \in G$\\
G --- open in $\tau$ \\
$F = X \setminus G$ --- closed
\begin{defn}
  $B_r (a) = \Set{x | \rho(x, a) < r}$ --- \textbf{open ball}
\end{defn}
\begin{stm}
  Any metric space gives rise to a topological space in a rather simple way.
  Let's call the subset $G \subset X$ open if and only if $\forall x \in G$
  there is some $r$ such that open ball $B_r(x)$ is contained in $G$. Then $\tau = \bigcup B_r (x)$
\end{stm}
\begin{stm}
  $b \in B_{r_1} (a_1) \cap B_{r_2} (a_2) \implies \exists r_3 > 0: B_{r_3}
  (a_3) \subset B_{r_1} (a_1) \cap B_{r_2} (a_2)$
\end{stm}
\noindent
\begin{ex}
  $\R, \rho(x, y) = |x - y|$, MS
\end{ex}
\begin{ex}
  $\bar{x} = (x_1, \dotsc, x_n) \in \R^n, \rho(\bar{x}, \bar{y}) = \sqrt{\sum\limits_{j = 1}^n(x_j - y_j)^2}, MS$
\end{ex}
\begin{ex}
    \hspace{-1.9em}$\begin{aligned}[t]
      \bar{x} &= (x_1, \dotsc, x_n, \dotso) \in \R^\infty \\
      \alpha\bar{x} &= (\alpha x_1, \dotsc, \alpha x_n, \dotsc) \\
      \bar{x} + \bar{y} &= (x_1 + y_1, \dotsc, x_n + y_n, \dotsc)
  \end{aligned}$

      Let's define $\alim{\bar{x}_m}{m \to \infty}$
      \begin{itemize}
          \item{in $\R^n$:}
              $\bar{x}_n \to \bar{x} \iff \forall j = 1, \dotsc, n\quad\ \ \:\,x_j^{(m)} \xrightarrow[m \to \infty]{} x_j$
          \item{in $\R^\infty$:}
              $\bar{x}_m \to \bar{x} \overset{def}{\iff} \forall j = 1,2,3,\dotso \quad x_j^{(m)} \xrightarrow[m \to \infty]{} x_j$
      \end{itemize}
\end{ex}
\begin{defn}
  $\rho(\bar{x}, \bar{y}) \defeq \sum\limits_{n = 1}^\infty \dfrac{1}{2^n}\underbrace{\dfrac{|x_n - y_n|}{1 + |x_n - y_n|}}_{\phi(|x_n - y_n|)}$
  --- \textbf{Urysohn metric}.

  \noindent
  \begin{minipage}{.65\linewidth}
    $\displaystyle\phi(t) = \dfrac{t}{1 + t} \\ \\
    \phi(t_1) + \phi(t_2) \geq \phi(t_1 + t_2) \\ \\
    \phi(t_1) + \phi(t_2) = \dfrac{t_1}{1 + t_1} + \dfrac{t_2}{1 + t_2} \geq \dfrac{t_1}{1 + t_1 + t_2} + \dfrac{t_2}{1 + t_1 + t_2} \\ \\
    \phi(t_1) + \phi(t_2) \geq \dfrac{t_1 + t_2}{1 + t_1 + t_2} = \phi(t_1 + t_2)$
  \end{minipage}%
  \begin{minipage}{.35\linewidth}
    \begin{tikzpicture}
      \begin{axis}[
        width = \linewidth,
        xmin  = 0,
        xmax  = 15,
        domain= 0:15,
        ymax  = 1.2,
        samples = 100,
        minor tick num = 0 ]
        \addplot[thick]{x/(1+x)};
      \end{axis}
    \end{tikzpicture}
  \end{minipage}
  \begin{stm}
      $\rho(\bar{x}_m, \bar{x}) \xrightarrow[m \to \infty]{} 0 \iff x_j^{(m)} \to x_j\ \forall j$
  \end{stm}
  \begin{proof}\leavevmode
    \begin{itemize}
      \item $\implies$

      $f(|x^{(n)}_k - x_k|) \leq 2^k \rho(x^{(n)}, x)$ \\
      Let $\rho(x^{(n)}, x) \le \dfrac{\epsilon}{2^k}$, then $f(|x^{(n)}_k - x_k|) < \epsilon$ \\
      $|x^{(n)}_k - x_k| = t = \dfrac{1}{1 - f(t)} - 1$, then $t \to 0$
      \item $\Leftarrow$

      Let's choose $k_0$ for which $\sum\limits_{k=k_0+1}^{\infty} \dfrac{1}{2^k} < \epsilon$ \\
      Let's choose $n_0$ for which $\forall k \leq k_0, n > n_0: |x_k^{(n)} - x_k| < \epsilon$. \\
      Then $\rho(x^{(n)}, x) < \sum\limits_{k=1}^{k_0} \dfrac{\epsilon}{2^k} + \epsilon < 2 \epsilon$ \\
      Letting  $\epsilon \to 0$, we get what we want \qedhere
    \end{itemize}
  \end{proof}
  In this way $\R^\infty$ is a metrizable space.
\end{defn}
\begin{ex}
$X, \rho(x, y) \defeq
\begin{cases}
    0, & x = y\\
    1, & x \neq y
\end{cases}$ --- \textbf{Discrete metric}. \\
$x_n \to x,\ \epsilon = \dfrac{1}{2},\ \exists M:\ m > M \implies \rho(x_m, x) < \dfrac{1}{2} \implies\\
\rho(x_m, x) = 0 \implies x_m = x$
\end{ex}
\begin{defn}
    \[(X, \tau);\ \forall A \subset X;\]
  \begin{align*}
     \inter{A}& \defeq \bigcup\limits_{G \subset A} G \textnormal{ is open}; \\
     \cl{A}& \defeq \bigcap\limits_{A \subset G} G \textnormal{ is closed}; \\
     \fr{A}& \defeq \cl{A} \setminus \inter{A}
  \end{align*}
\end{defn}
\noindent
$(X, \rho);$ Having a metric space one can describe closure of a set.
\begin{gather*}
    \rho(x, A) \defeq \inf\limits_{a \in A}\rho(x, a) \\
    \rho(A, B) \defeq \inf\limits_{\substack{a \in A\\b \in B}}\rho(a, b) \\
    \rho(x, A) = f(x), x \in X
\end{gather*}
\begin{stm}
  Function $f(x)$ is continuous.
\end{stm}
\begin{proof}
  $\forall x, y \in X \\
  f(x) = \rho(x, A) \underset{\forall \alpha \in A}{\leq} \rho(x, \alpha) \leq \rho(x, y) + \rho(y, \alpha) \\
  \forall \epsilon > 0\ \exists \alpha_\epsilon \in A:\ \rho(y, \alpha_\epsilon) < \rho(y, A) + \epsilon = f(y) + \epsilon \\
  f(x) \leq f(y) + \epsilon + \rho(x, y),\ \epsilon \to 0 \\
  \begin{cases}
    f(x) \leq f(y) + \rho(x, y) \\
    f(y) \leq f(x) + \rho(x, y)
  \end{cases} \implies |f(x) - f(y)| \leq \rho(x, y)$
\end{proof}
\begin{stm}
  $x \in \cl{A} \iff \rho(x, A) = 0$
\end{stm}
Let's look at the metric spaces in terms of separation of sets from each other by open sets. \\
$x, y \\
r = \rho(x, y) > 0 \\
B_{\dfrac{r}{3}}(x),\ B_{\dfrac{r}{3}}(y)$ \\
In any metric space separability axiom is true.
\begin{thm}
  Any metric space is a normal space, \\i.e.
  $\forall\ closed\ disjoint\ F_1, F_2 \in X,\ \exists\ open\ disjoint\ G_1, G_2\colon F_j \in G_j,\ j = 1, 2$
\end{thm}
\begin{proof}
  $g(x) = \dfrac{\rho(x, F_1)}{\rho(x, F_1) + \rho(x, F_2)}$ --- continuous on X \\
  $x \in F_1,\ \cl{F_1} = F_1,\ \rho(x, F_1) = 0,\ g(x) = 0 \\
  x \in F_2,\ g(x) = 1$ \\
  Let's look at $(-\infty; \dfrac{1}{3}), (\dfrac{2}{3}, \infty)$ --- by continuity their inverse images under $g$ are open. \\
  $G_1 = g^{-1}(-\infty; \dfrac{1}{3}) \\
  G_2 = g^{-1}(\dfrac{2}{3}; \infty)$
\end{proof}
\begin{defn}
  Metric space is \textbf{complete} if $\rho(x_n, x_m) \to 0 \implies \exists x = \lim x_n \\
  \R^\infty$ -- complete (by completeness of the rational numbers). \\
  In complete metric spaces the nested balls principle is true.
\end{defn}
\begin{thm}
  X -- complete metric space, $\overline{V}_{r_n}$ -- system of closed balls.
  \begin{enumerate}
      \item $\overline{V}_{r_{n + 1}} \subset \overline{V}_{r_n}$ -- the system is nested.
      \item $r_n \to 0$
    \end{enumerate}
  \underline{Then:} $\bigcap\limits_n \overline{V}_{r_n} = \{a\}$
\end{thm}
\begin{proof}
  Let $b_n$ be centers of $\overline{V}_{r_n}, \\
  m \geq n,\ b_m \in \overline{V}_{r_n},\ \rho(b_m, b_n) \leq r_n \to 0\ \forall m \geq n \\
  \rho(b_m, b_n) \to 0 \xRightarrow{compl.} \exists a = \lim b_n$
  Since the balls are closed a $\in$ every ball. \\
  $r_n \to 0 \implies$ there is only one common point.
\end{proof}
\noindent
$(X, \tau)$ --- topological space
$\\A \subset X,\ \tau_a = \Set{G \cap A, G \in \tau}$ --- topology induced on $A$
\begin{defn}
  $X \textnormal{--- metric space},\ A \subset X,\ \cl{A} = X$ \\
  \underline{Then:} A -- \textbf{dense} in X \\
  \underline{If} $\inter{\cl{A}} = \varnothing$ A -- \textbf{nowhere dense} in X.
\end{defn}
\begin{note}
  It is easy to understand, that in metric spaces nowhere density means the following: \\
  $\forall \text{ ball } V\ \exists V^{'} \subset V\colon V^{'}$ contains no
  points from A.
\end{note}
\begin{defn}
  $X$ is called \textbf{first Baire category set}, if it can be written as at most
  countable union of $x_n$ each nowhere dense in $X$.
\end{defn}
\begin{thm}[Baire category theorem]
  Complete metric space is second Baire category set in itself.
\end{thm}
\begin{proof}
  Let $X$ be first Baire category set. \\
  $X = \bigcup\limits_n X_n \quad \forall \overline{V}\ X_1\ \textnormal{is nowhere dense}. \\
  \overline{V}_1 \subset \overline{V}\colon\ \overline{V}_1 \cap X_1\ = \varnothing \\
  X_2\ \textnormal{is nowhere dense}\ \overline{V}_2 \subset \overline{V}_1 \colon \overline{V}_2 \cap X_2 = \varnothing \\
  r_2 \leq \dfrac{r_1}{2} \\
  \vdots \\
  \{\overline{V}_n\},\ r_n \to 0,\ \bigcap\limits_n \overline{V}_n = \{a\},\ X =
  \bigcup X_n,\ \exists n_0 \colon a \in X_{n_0} \\
  X_{n_0} \cap \overline{V}_{n_0} = \varnothing \contr\ a \in \overline{V}_{n_0}$
\end{proof}
\begin{cor}
  Complete metric space without isolated points is uncountable.
\end{cor}
\begin{proof}
  No isolated points are present $\implies$ every point in the set is nowhere dense in it. Let $X$ be countable:
    $X = \bigcup\limits_n \{X_n\}$, then it is first Baire category set. $\contr$
\end{proof}
\begin{defn}
  $K$ --- \textbf{compact} if
  \begin{enumerate}
    \item $K = \cl{K}$
    \item \label{itm:second}$x_n \in K\ \exists n_1 < n_2 < \dotso\ x_{n_j} - \textnormal{converges in $X$}$.
  \end{enumerate}
  If only \ref{itm:second} is present, the set is called \textbf{precompact}.
\end{defn}
\begin{thm}[Hausdorff]
  Let $X$ --- metric space, $K$ --- closed in $X$. \\
  \underline{Then:} $K$ --- compact $\iff$ $K$ --- totally bounded, \\
  i.e. $\forall \epsilon > 0\ \exists a_1,\dotsc, a_p \in X \colon\ \forall b \in K\ \exists a_j \colon\ \rho(a_j, b) < \epsilon \\
  (a_1, \dotsc, a_p - finite\ \epsilon-net)$
\end{thm}
\begin{proof}\leavevmode
  \begin{itemize}
    \item Totally bounded $\implies$ compact

      $K$ is totally bounded, $x_n \in K\ n_1 < n_2 < \dotsb < n_k < \dotsb,$
      $x_n$ converges in $K$
      \[\epsilon_k \downarrow \to 0\ \epsilon_1 \quad K \subset \bigcup\limits_{j = 1}^p \overline{V}_j,\ rad = \epsilon_1\qquad \text{($\epsilon_1$-net)} \]
      $n$ is finite $\implies$ one ball will contain infinetely many $x_n$ elements.

      Let's look at $\overline{V}_{j_0} \cap K$ --- totally bounded $= K_1, \diam{K_1} \leq 2\epsilon_1$ \\
      $\epsilon_2\quad K_1 \subset \bigcup\limits_{j =1}^n
      \overline{V^{'}}_{j},\ rad = \epsilon_2.$

      Then one of $\overline{V'}$ contains infinitely many elements of the sequence contained in $K_1$.

      $\overline{V'}_{j_0} \cap K_1 = K_2,\ \diam{K_2} \leq 2\epsilon_2$ and so on.

      $K_n \supset K_{n+1} \supset K_{n+2} \supset \dotso,\ \diam{K_N} \leq 2\epsilon_n
      \xRightarrow{\text{by compl.}} \underbrace{\bigcap\limits_{n = 1}^\infty K_n}_{\diam{K_n} \to 0,\ \{x\}} \neq \varnothing$

      Take $x_{n_1}$ from $K_1$, $x_{n_2}$ from $K_2 \dotso$
    \item Compact $\implies$ totally bounded

      $K$ --- compact $\forall \epsilon\ \exists$ finite $\epsilon$-net? \\
      By contradiction: $\exists\epsilon_0 > 0\colon$\ finite $\epsilon_0$-net is impossible to construct. \\
    $\forall x_1 \in K\ \exists x_2 \in K \colon\ \rho(x_1, x_2) > \epsilon_0$ (or else system of $x_1$ --- finite $\epsilon$-net) \\
    $\{x_1, x_2\}$ - choose $x_3 \in K\colon \rho(x_3, x_i) > \epsilon_0,\ i = 1, 2$ and so on. \\
    $x_n \in K:\ n\ \neq m\ \rho(x_n, x_m) > \epsilon_0$ --- contains no converging subsequence $\implies$
    set is not a compact. $\contr$ \qedhere
  \end{itemize}
\end{proof}
\section{Normed spaces}
\begin{defn}
  $X$ --- \textbf{linear set}, $x + y, \alpha \cdot x$, $\alpha \in \R$ \\
  The purpose of norm definition, is to construct a topology on $X$, so that 2 linear operations are continuous on it.
\end{defn}
$\phi\colon X \to \R\colon$
\begin{enumerate}
\item $\phi(x) \geq 0,\ = 0 \iff x = 0$
\item $\phi(\alpha x) = |\alpha| \phi(x)$
\item $\phi(x + y) \leq \phi(x) + \phi(y)$
\end{enumerate}
\begin{defn}
  $\phi$ --- \textbf{norm} on $X$, $\phi(x) = \|x\|$
\end{defn}
$\rho(x, y) \defeq \|x - y\|$ --- metric on $X$.
\begin{defn}
  $\\(X, \|\cdot\|)$ --- \textbf{normed space} --- special case of metrical space.
\end{defn}
\noindent
$x = \lim x_n \overset{def}{\implies} \rho(x_n, x) \to 0 \iff \|x_n - x\| \to 0$
\begin{stm}
  In the topology of a normed space linear operations are continuous on $X$.
\end{stm}
\begin{proof}\leavevmode
  \begin{enumerate}
  \item
    $\begin{aligned}[t]
      x_n \to x,\ y_n \to y;\ \|(x_n + y_n) - (x + y)\| & = \|(x_n - x) + (y_n - y)\|  \leq \\
      & \leq  \tendsto{\|x_n - x\|}{0} + \tendsto{\|y_n - y\|}{0} \\
      & \implies x_n + y_n \to x + y
    \end{aligned}$
  \item
    $\begin{aligned}[t]
       \alpha_n \to \alpha,\ x_n \to x;\ \|\alpha_n x_n - \alpha x\| & =
        \|(\alpha_n - \alpha)x_n + \alpha(x_n - x)\| \leq \\
        & \leq \tendsto{|\alpha_n - \alpha|}{0} \cdot \underbrace{\|x_n\|}_{bounded} + \tendsto{\alpha\|x_n - x\|}{0}
    \end{aligned}$ \\
    $x_n \to x \implies \|x_n\|$ --- bounded. \\
    $\alpha_x x_n \to \alpha x$ \qedhere
  \end{enumerate}
\end{proof}
\begin{stm}
  From the triangle inequality $\bigl|\|x\| - \|y\|\bigr| \leq \|x - y\| \\
  x_n \to x \implies \|x_n\| \to \|x\|$ \\
  Norm is continious.
\end{stm}
\begin{ex}
  $\R^n$
  \begin{enumerate}
  \item $\|\bar{x}\| = \sqrt{\sum\limits_{k = 1}^n x_k^2}$
  \item $\|\bar{x}\|_1 \defeq \sum\limits_{k = 1}^n|x_k|$
  \item $\|\bar{x}\|_2 \defeq \max \{|x_1|, \dotsc, |x_n|\}$
  \item $C[a, b]$ --- functions continuous on $[a, b];\ \|f\| = \max\limits_{x \in [a, b]}|f(x)|$
  \item $L_p (E) = \Set{f \textnormal{ --- measurable},\ \int\limits_E \abs{f}^p < +
    \infty}\\
    p \geq 1,\ \|f\|_p = \biggl(\displaystyle\int\limits_E |f|^p\biggr)^{\dfrac 1p}$
  \end{enumerate}
\end{ex}
Because the set of points is the same, arises the question about convergence
comparison. \\
$\|\cdot\|_1 \sim \|\cdot\|_2,\ x_n \overset{\|\cdot\|_1}{\to} x \iff x_n \overset{\|\cdot\|_2}{\to} x$
\begin{stm}
  $\\\|\cdot\|_1 \sim \|\cdot\|_2 \iff \exists a, b > 0\colon \forall x \in X
  \implies a\|x_1\|_1 \leq \|x\|_2 \leq b \|x\|_1$
\end{stm}
\begin{thm}[Riesz]
  $X,\ \dim{X} < +\infty$ --- linear set. \\
  \underline{Then:} Any pair of norms in $X$ are equivalent.
\end{thm}
\begin{proof}
  $l_1, \dotsc, l_n$ --- linearly independent from $X$. $\forall x \in X =
  \sum\limits_{k = 1}^n \alpha_k l_K$
  \[\bar{x} \leftrightarrow (l_1, \dotsc, l_n) = \bar{l} \in \R^n\]
  Let $\|\cdot\|$ --- some norm in $X$.
  \begin{gather*}
  \|x\| \underset{\triangle}{\leq} \sum\limits_{k = 1}^n \|l_k\| |\alpha_k|
  \underset{\text{Cauchy}}{\leq} \underbrace{\sqrt{\sum\limits_{k=1}^n \|l_k\|^2}}_{const(B), B - basis}
  \equalto{\sqrt{\sum\limits_{k=1}^n |\alpha_k|^2}}{\|\bar{\alpha{}}\| = \|x\|_1} \\
  \|x\|_1 = \sqrt{\sum\limits_{k=1}^n \|\alpha_k\|^2},\ x = \sum \alpha_k l_k  \\
  \|x\| \leq b \|x\|_1 \\
  ?\exists a > 0\colon a\|x\|_1 \leq \|x\| \implies \|\cdot\| \sim \|\cdot\|_1 \\
  \end{gather*}
  Let $f(\alpha_1, \dotsc, \alpha_n) = \norm{\sum\limits_{k = 1}^n \alpha_k l_k}$
  \begin{align*}
    \\|f(\bar{\alpha} + \Delta\bar{\alpha}) - f(\bar\alpha)| = &
      \abs{\rule{0em}{2em}\norm{\sum_{k=1}^n
    \alpha_k l_k + \sum_{k=1}^n \Delta \alpha_k l_K } - \norm{\sum_{k=1}^n
    \alpha_k l_k}} \leq \\ & \norm{\sum_{k=1}^n \Delta \alpha_k l_k} \leq \tendsto{\sum
    \| l_k\| |\Delta \alpha_k|}{0, \Delta \alpha_k \to 0} \implies \text{$f$ is continuous on $\R^n$}
  \end{align*}

  $S_1 = \Set{\sum\limits_{k=1}^n \abs{\alpha_k}^2 = 1} \subset \R^m$, f --- continuous
  on $S_1$, $S_1$ --- compact, $\bar{\alpha}^* \in S_1$ \\
  By Weierstrass theorem there exists a point $\alpha^* \in S_1$ on a sphere,
  in which function $f$ achieves its minimum
  $\implies \forall \alpha \in S_1\ f(\bar{\alpha}^*) \leq f(\bar{\alpha})$

  If $f(\bar{\alpha}^*) = 0$,
  then $\norm{\sum\limits_{k=1}^n \alpha_k^* l_k} = 0 \implies
  \sum\limits_{k=1}^n \alpha_k^* l_k = 0,\ \bar{\alpha}^* \in S_1$, \\
  but $l_1 \dots l_n$ are linearly independent $\contr
  \implies \min\limits_{S_1} f = m > 0$
  \begin{align*}
    \|x\| = \norm{\sum_{k=1}^n \alpha_k l_k}  = f(\bar{\alpha}) =
    \sqrt{\sum_{k=1}^n \alpha_k^2} \cdot \norm{\sum
    \underset{\beta_k}{\boxed{\dfrac{\alpha_k}{\sqrt{\sum_{k=1}^n \alpha_k^2}}}}
    \cdot l_k} & \geq ,\ \bar{\beta} = (\beta_1 \dots \beta_n) \in S_1 \\
    & \geq m \cdot \|x\|_1,\ a = m \qedhere
  \end{align*}
\end{proof}
\begin{cor}
  $X$ --- NS, $Y \subset X, \dim{Y} < + \infty \implies Y = \cl{Y}$
  \begin{note}
    Functional analysis differentiates between linear subset (set of points,
    closed by addition and scalar multiplication) and linear subspace (closed
    linear subset).
  \end{note}
\end{cor}
\begin{proof}
  $Y = \L(l_1, \dotsc, l_n) = \Set{\sum\limits_{i=1}^n \alpha_il_i | l_1, \dotsc, l_n - \text{lin. indep.}} \\
  y_m \in Y, y_m \to y$ in $X \implies y \in Y?\\
  \norm{y_m - y} \to 0 \implies \norm{y_m - y_p} \to 0,\ m,p \to \infty \\
  \norm{y}, y \in Y.\\
  \textnormal{By Riesz theorem all norm in Y are equivalent.} \\
  y = \sum\limits_{j=1}^n \alpha_j l_J, \norm{y}_0 = \sqrt{\sum\limits_{j=1}^n
    \alpha_j^2}$ --- some norm (by linear independance). \\
  By Riesz theorem $\|y\| \sim \|y\|_0 \\
  \underbrace{\|y_m - y_p\|}_{\in Y} \to 0 \implies \|y_m - y_p\|_0 \to 0 \\
  \bar{\alpha}=(\alpha_1, \dotsc, \alpha_n) \in \R^n\ y_m = \sum\limits_{i = 1}^n \alpha_i^{(m)}l_i \\
  |\alpha_i^{(m)} - \alpha_i^{(l)}| \to 0\ \forall i = 1, \dotsc, n;\
  \bar{\alpha} = (\alpha_1^{(m)}, \dotsc, \alpha_n^{(m)}) \to \alpha^* =
  (\alpha_1^*, \dotsc , \alpha_n^*) \\
  y^* = \sum\limits_{i=1}^n \alpha_i^* l_I \in Y,\ \|y_m - y\| \to 0, y = y^*
  \implies y \in Y$
\end{proof}
\begin{defn}
  If normed space if complete, then it is called \textbf{B-space} or \textbf{Banach space}.
\end{defn}
\begin{ex}
 $C[a, b]$ --- functions continuous on $[a, b]$.
\end{ex}
\begin{ex}
  Lebesgue space,
  $p \geq 1, L_p(E) = \Set{f \textnormal{ is measurable on $E$},\ \int\limits_E \abs{f}^P < + \infty}$.
\end{ex}
If $X$ --- Banach space, \\
$\begin{aligned}[t]
& \sum_{n = 1}^\infty x_n = \lim_{n \to \infty}
\sum_{k = 1}^n x_k,\ \sum_{n=1}^\infty \|x_n\| < + \infty \\
& \|S_n - S_m\| = \norm{\sum_{k = m + 1}^n x_k} \leq \sum_{m + 1}^n
\|x_k\| \xrightarrow[n, m \to \infty]{} 0 \\
& \implies \|S_n - S_m\| \to 0 \implies  \exists \lim_{n \to \infty} S_n,
\sum_{k=1}^n x_k \text{--- converges.}
\end{aligned}$ \\
In Banach spaces works the theory of absolute convergence of numerical series.
\begin{lemma}[Riesz's lemma about almost perpendicular]
  $Y$ --- eigen subspace of $X$ --- normed space.
  $\forall \epsilon \in (0, 1)\ \exists z_\epsilon \in X \colon$
\begin{enumerate}
\item $\|z_\epsilon\| = 1$
\item $\rho(z_\epsilon, Y) > 1 - \epsilon$
\end{enumerate}
\end{lemma}
\begin{proof}
  $\exists x \notin Y\ d = \rho(x, Y),\ d = 0\ \exists y_n \in Y\colon \|x -
  y_n\| < \dfrac{1}{n},\ n \to \infty,\ y_n \to x \\
  Y = \cl{Y} \implies x \in Y \contr x \notin Y,\ d > 0 \\
  \forall \epsilon \in (0, 1)\ \dfrac{1}{1 - \epsilon} > 1\ \exists y_\epsilon
  \in Y\colon \|x - y_\epsilon\| < \dfrac{1}{1 - \epsilon}d \\
  z_\epsilon = \dfrac{x - y_\epsilon}{\|x - y_\epsilon\|},\ \|z_\epsilon\| = 1,\
  \forall y \in Y\ \|z_\epsilon - y\| = \norm{\dfrac{x - y_\epsilon}{\|x -
      y_\epsilon\|}} = \dfrac{\|x - \overbrace{(y_\epsilon + \|x - y_\epsilon\| \cdot y)}^{\in Y}\|
    \geq d}{\|x- y_\epsilon\| < \dfrac{1}{1 - \epsilon}d} > 1 - \epsilon$
\end{proof}
\begin{cor}
  $\dim{X} = + \infty$, $S$ --- sphere in $X$, $r_S = 1 \Set{x | \|x\| = 1}
  \implies S$ --- not a compact.
\end{cor}
\begin{proof}
  $\forall x_1 \in S,\ Y_1 = \L\{x_1\}$ --- finite dimensional linear set.
  $\implies\ \text{closed in}\ X \implies Y_1$ --- subspace. $\dim{X} = + \infty
  \implies Y_1$ --- eigen subspace. \\
  Then by the Riesz lemma:
  \begin{align*}
    & \exists x_2 \in S\colon \|x_2 - x_1\| > \dfrac 12 \\
    & Y_2 = \L\{x_1, x_2\}\ \exists x_3 \in S\colon \|x_3 - x_j\| > \dfrac 12,\ j = 1,2
  \end{align*}
  Continue by induction. Because $\dim{X} = + \infty$ the process willl never
  stop. \\
  $x_n \in S \colon \|x_n - x_m\| > \dfrac 12,\ n \neq m$ --- obviously we
  cannot extract converging subsequence. $\implies S$ --- not a compact.
\end{proof}
\section{Inner product (unitary) spaces}
\begin{defn}
  $X$ --- linear space. \\
  $\phi \colon X \times X \to \R$
  \begin{enumerate}
      \item $\phi(x, x) \ge 0,\quad \phi(x, x) = 0 \iff x = 0$
  \item $\phi(x, y) = \phi(y, x)$
  \item $\phi(\alpha x + \beta y, z) = \alpha \phi(x, z) + \beta \phi(y, z)$
  \end{enumerate}
  $\phi$ --- \textbf{inner product}. \\
  $\phi(x, y) = \langle x, y \rangle$
\end{defn}
\begin{defn}
  $(X, \langle \cdot, \cdot \rangle)$ --- \textbf{inner product space}.
\end{defn}
\begin{ex}
  $\R^n, \langle \bar{x}, \bar{y} \rangle = \sum\limits_{j = 1}^n x_j y_j$
\end{ex}
\begin{stm}[Schwarz]
  $\forall x, y \in X \quad \abs{\langle x, y \rangle} \leq \sqrt{\langle x,
    x \rangle} \cdot \sqrt{\langle y, y \rangle}$
\end{stm}
\begin{proof}
  $\begin{aligned}[t]
    & \lambda \in \R \\
    & f(\lambda) =
      \equalto{\langle \lambda x + y, \lambda x + y \rangle}
      {\lambda^2 \langle x, x \rangle + 2 \lambda \langle x, y \rangle + \langle y, y \rangle} \geq 0 \\
    & D = 4 \langle x, y \rangle^2 - 4 \langle x, x \rangle \cdot \langle y, y
    \rangle \leq 0 \qedhere % FIXME: \qedhere should not be here!
  \end{aligned}$
\end{proof}


\begin{cor}[Cauchy inequality for sums]
  Consider $X = \R^n, \norm{x} \defeq \sqrt{\langle x, x \rangle}$. Then
  \[
  \norm{x+y}^2 = \inprod{x+y, x+y} = \norm{x}^2 + 2 \cdot \!\!\underbracket{\inprod{x, y}}_{{} \le \norm{x} \cdot \norm{y}}\!\! + \norm{y}^2 \le \bigl(\norm{x} + \norm{y}\bigr)^2
  \]
\end{cor}

Any inner product space is a special case of a normed space. The specifics is that we can measure the angles between points:
\[
  x \perp y \iff \inprod{x, y} = 0
\]
In this case the Pythagorean theorem takes place:
\[
\norm{x+y}^2 = {\norm x}^2 + {\norm y}^2
\]

\noindent In inner product spaces the parallelogram law plays a significant role:
\[
\norm{x+y}^2 + \norm{x-y}^2 = 2 \norm{x}^2 + 2 \norm{y}^2 \quad \forall x, y \in X
\]

% не хуйня ли часом с этого места?
%Да вроде нет, In an inner product space, the norm is determined using the inner
%product: \|x\|^2=\langle x, x\rangle.\ (c) https://en.wikipedia.org/wiki/Parallelogram_law
In an inner product space norm is determined by inner product:
$\|x\|^2 = \inprod{x, x}$ \\
It can be proved that if parallelogram law holds, then the norm must be
determined by some inner product. Let $X$ be some normed space, $x \in X$, then
$\inprod{\cdot, \cdot} \mapsto \norm{x} = \sqrt{\inprod{x, x}}$.
For any norm satisfying the parallelogram law, the inner
product generating the norm is unique.

\begin{ex}
  $C_{[a, b]},\ \|f\| = \max\limits_{x \in [a, b]}|f(x)|$, $\|f\|$ doesn't satisfy
  the parallelogram law and thus is not determined by any inner product. This
  fact implies that $C_{[a, b]}$ is not an inner product space.
\end{ex}

\begin{defn}
  \textbf{Orthonormal set} --- a set of points $\Set{l_1, l_2, \dotsc}$ (may be finite):
  \begin{enumerate}
    \item $\norm{l_i} = 1$
    \item $l_i \perp l_j, \quad i \ne j$
  \end{enumerate}
\end{defn}
\noindent Every orthonormal set is linearly independent.

\begin{defn}
  Let $x \in X, \Set{l_i}$ --- ONS. Then \\
  $\inprod{x, l_j}$ --- \textbf{Fourier coefficient}, \\
  $\sum\limits_j \inprod{x, l_j} l_j$ --- \textbf{Fourier series} of point $x$.
\end{defn}
\noindent Fourier series is a special case of orthogonal series.

\begin{defn}
  $\sum\limits_j x_j$ --- orthogonal series $\iff x_i \perp x_j, \quad i \ne j$
\end{defn}

\noindent Let $\sum\limits_{j=1}^\infty x_j, S_m = \sum\limits_{j=1}^m x_j$. Then
\[\textstyle
\norm{S_m}^2 = \bigl\langle \sum\limits_{j=1}^m x_j,\sum\limits_{j=1}^m x_j \bigr\rangle = \sum\limits_{j=1}^m \norm{x_j}^2
\]

\noindent This fact allows us to effectively build the theory of orthogonal series.

An important problem is concerned with Fourier series. Let $X$ is a normed space, $Y$ is a subspace of $X$,
\[
\forall x \in X \quad E_Y(x) = \rho(x, Y) = \inf_{y \in Y} \norm{x-y}
\]

\begin{defn}
  $E_Y (x)$ --- \textbf{best approximation} of point $x$ with points of the subspace $Y$, if $\exists y^* \in Y \quad E_y(x) = \norm{x - y^*}$ --- then $y^*$ is an element of best approximation.
\end{defn}

\begin{thm}[Borel]
  $\dim Y < +\infty \implies \forall x \in X \quad \exists y^* \in Y$ --- element of best approximation.
\end{thm}
\begin{proof}
  $Y = \L(\underbracket{l_1, l_2, \dotsc, l_n}_{\text{lin. indep.}})$

  Consider $f(\alpha_1, \dotsc, \alpha_n) = \bigl\| x - \sum\limits_{k=1}^n \alpha_k l_k \bigl\| \to \min$. By the triangle inequality for norm, $f(\bar \alpha)$ is continous on $\R^n, f \ge 0, E_Y(x) = \inf f(\bar \alpha)$.
  It is easy to find that there always is a ball $B(0, r) \subset \R^n$, outside
  of which $f > 2E_Y(x)$. So, $E_Y(x)$ is somewhere inside. But $f$ is
  continuous, the ball is compact, so, by the Weierstrass theorem, the minimum
  exists and it is located on the sphere $S(0, r)$.
\end{proof}

For abstract Fourier series the Borel theorem can be significantly strengthened by specifying the best approximation element.

\begin{thm}[extreme quality of Fourier series' partial sums]
    $\Set{e_j}$ --- ONS in $X$ \\
    $H_n = \L(l_1, \dotsc, l_n)$ \\
    $E_{H_n}(x), S_n(x) = \sum\limits_{j=1}^n \inprod{x, l_j} l_j \implies E_{H_n}(x) = \norm{x-S_n(x)}$
\end{thm}
\begin{proof}
  $y = \sum\limits_{j=1}^n \alpha_j l_j \in H_n$
  \begin{align*}
    \norm{x-y}^2 &= \inprod{x - \sum \alpha_j l_j, x - \sum \alpha_j l_j} = \norm{x}^2 - 2 \sum \alpha_j \inprod{x, l_j} + \sum{\alpha_j^2} = \\
    {} &= {\underbracket{\norm{x}}_{\mathrm{const}}}^2 + \sum (\alpha_j - \inprod{x, l_j})^2 - \underbracket{\sum \inprod{x, l_j}^2}_{\mathrm{const}} \to \min
  \end{align*}
  \noindent So, the sum goes to minimum when the second summand is minimal. Obviously, it's minimal when $\forall (\alpha_j - \inprod{x, l_j}) = 0$. $E_Y(x)$ --- Fourier sum.
\end{proof}

\begin{cor}[Bessel's inequality]
  $\sum\limits_j \inprod{x, l_j}^2 \le \norm{x}^2$
\end{cor}
\begin{proof}
  $ 0 \le \norm{x - y^*}^2 = \norm{x}^2 - \sum\limits_j \inprod{x, l_j}^2 $
\end{proof}
\begin{cor}
  The series of Fourier coefficients' squares always converges
\end{cor}
\section{Hilbert space.}
\begin{defn}
  \textbf{Hilbert space} --- complete, infinite dimensional, inner product space.
\end{defn}
\begin{ex}
  $L_2(E)$ --- Hilbert space. \\
  $\inprod{f, g} = \int\limits_E f \cdot g\ d\mu$ \\
  $l_2 = \Set{(x_1, \dotsc, x_n, \dotsc) | \sum\limits_{n = 1}^\infty x_n^2 < +\infty}$ \\
  $\inprod{\bar{x}, \bar{y}} = \sum\limits_{n = 1}^\infty x_n y_n,\ E = \N,\ \mu\{m\} = 1$
\end{ex}
\noindent
When we have completeness we can define orthonormal basis.
\begin{defn}
  $H,\ \{l_n\}$ --- ONS $\colon \forall x = \sum\limits_{n = 1}^\infty \alpha_n l_n
  \implies \inprod{x, l_m} = \sum\limits_{n = 1}^\infty \alpha_n \inprod{l_n, l_m} = \alpha_m$ \\ 
In this sense basis decomposition is always a Fourier series.
  \begin{enumerate}
  \item Complete ONS\@: $H = \cl{\L\{l_1, l_2, \dots\}}$
  \item Closed ONS\@: $\forall m\ \inprod{x, l_m} = 0 \implies x = 0$.
  \end{enumerate}
\end{defn}
\begin{stm}
  In Hilbert spaces two of the properties outlined above are equivalent. \\
  $\sum\limits_{n = 1}^\infty y_n$ in $H$ --- orthogonal series. \\
  $\|S_n - S_m\|^2 = \sum\limits_n^m \|y_k\|^2 \\
  \|S_n - S_m\| \to 0 \iff \sum\limits_n^m \|y_k\|^2 \to 0$ \\
  in $H\ \sum\limits_1^\infty \|y_k\|^2 < + \infty$
\end{stm}
\noindent
ONS $x \mapsto \sum\limits_{k = 1}^\infty \inprod{x, l_k} l_k$ \\
$\sum\limits_{k = 1}^\infty \inprod{x, l_k}^2 \leq \|x\|^2 < +\infty$
\begin{stm}
  In Hilbert space Fourier series converges for any point.
\end{stm}                                    
\begin{proof}
  Complete ONS. \\
  $\forall x \in H\ \forall \epsilon > 0\ \exists \sum\limits_{j =
    1}^p \alpha_{kj}l_{kj}\colon \underbrace{\|x - \sum\limits_{j = 1}^p
    \alpha_{kj}l_{kj}\|^2}_{\geq \|x - \sum\limits_{j = 1}^{k_p} \inprod{x, l_j} l_j\|^2}
  \leq \epsilon^2$ \\
  $S_m(x)$ by extremety $\|x - S_{m + p}(x)\|^2 \leq \|x - S_m(x)\|^2$ \\
  Implies partial sums go to x, $x = \sum\limits_{j = 1}^\infty \inprod{x, l_j} l_j$
  If all fourier coefficients are zero, it means the ONS is closed $(x = 0)$. \\
  Closed ONS. \\
  $y = \sum\limits_{j = 1}^\infty \underbrace{\inprod{x, l_j}}_{ = \inprod{y,
      l_j}} l_j \implies \inprod{y, l_j} = \inprod{x, l_j} \implies \inprod{y - x,
    l_j} = 0$ \\
  Because ONS is closed $y - x = 0,\ y = x$. Thus we can decompose any point into
  Fourier series, and this implies that ONS is complete.
\end{proof}
Considering basis existance.
\begin{defn}
  Topological space is called \textbf{separable} if there exists countable dense set in it. \\
  $X = \cl{\{a_1, \dotsc, a_n, \dotsc\}}$
\end{defn}
$H$ --- separable, $a_1, \dotsc, a_n, \dotsc$ We can orthogonalize these dots
(Gramm-Shmidt), and we will get complete ONS.
This means space separability is equivalent to basis existance.
\begin{thm}[about best approximation in $H$]
  $H$ --- HS, $M$ --- closed convex subset of $H$, then $\forall x \in H \ \exists!
  y \in M \colon \|x -y\| = \inf\limits_{z \in M}\|x - z\|$.
  $M$ has element of best approximation for any $x$ from $X$, and only one.
\end{thm}
\begin{proof}
  $x \in H,\ H_1,\ H_2 = H_1^{\perp} \\
  \exists x_1 \in H_1 \colon \|x - x_1\| = \inf\limits_{n \in H_1}\|x - n\| \\
  x_2 = x - x_1\ \in H_2 ? \\
  \forall y \in H_1 y \perp x_2,\ \lambda > 0,\ x_ 1+ \lambda y \in H_1 (H_1
  \text{--- subspace})$

  \noindent
  By definition of best approximation element
  $\|x - (x_1 - \lambda^2)\| \geq \|x - x_1\|^2 \quad \forall \lambda > 0 \\$
  Let's expand squared norms via inner product. \\
  $\langle\underbrace{x - x_1}_{x_2} - \lambda y, x - x_1 - \lambda y\rangle \geq
  \inprod{x - x_1, x - x_1} \\
   \inprod{x_2 - \lambda y, x_2 - \lambda y} \geq \inprod{x_2, x_2} \\
   \inprod{x_2, x_2} - 2 \lambda \inprod{y, x_2} + \lambda^2 \inprod{y, y} \geq
   \inprod{x_2, x_2}\ : \lambda > 0 \\
   2 \inprod{y, x_2} \leq \lambda \inprod{y, y},\ \lambda \to +0 \implies
   \inprod{y, x_2} \leq 0 \\$ 
   Substitute $y$ for $-y$:
   $\inprod{-y, x_2} \leq 0 \implies \inprod{y, x_2} \geq 0 \implies \inprod{y, x_2} = 0$
\end{proof}
\section{Countably-normed spaces.}
\begin{defn}
  $X$ --- linear set, $p$ --- halfnorm (function satisfying all 3 norm axioms,
  but the first one is weakened $p(x) \geq 0$, but p can be zero on non-zero
  $x$).
  \begin{enumerate}
  \item $p(x) \geq 0$
  \item $p(\lambda x) = |\lambda| p(x)$
  \item $p(x + y)$
  \end{enumerate}
\end{defn}
\begin{defn}
  $p_1, p_2, \dotsc, p_n, \dotsc$ --- halfnorms $\forall n p_n(x) = 0 \implies x
  = 0$ $(X, p_1, p_2, \dotsc, p_n, \dotsc )$ --- \textbf{countably normed space}.
\end{defn}
$x = \lim x_m \iff \forall n \in \N \lim\limits_{m \to \infty} (x_m - x ) = 0\ \|\cdot\|$
$x_m \to x^{'} \implies \forall n\ p_n(x_m - x^{'}) \to 0
x_m \to x^{''} \implies \forall n\ p_n$
If in countably-normed space we assume $p(x, y) = \sum\limits_{n = 1}^\infty
\dfrac{1}{2^n}\dfrac{p_n(x - y)}{1 + p_n(x - y)} \R^\infty$
Thus countably-normed space is always metrizable.
In countably-normed space two linear operations $(x + y, \lambda x)$ are
continuous, which means any countably normed space is also a topological vector space.
\begin{ex}
  $C^\infty[a, b] = \Set{x(t), t \in [a, b] | x(t) \text{--- infinetely diff.}} \\
  p_n(x) = \max\limits_{[a, b]}\abs{x^{(n)}(t)}\ n = 0,1,2,\dotsc$
\end{ex}
From the next theorem we will see that $C^\infty[a, b]$ is non-normalizable (has no norm convergence
by which is equivalent to halfnorm convergence).
We will try to deduce the criteria of countably-normed space normalizability.
\begin{defn}
  System of halfnorms is called \textbf{monotonous} if $\forall x \in X,\
  \forall n \in \N\ p_n(x) \leq p_{n + 1}(X)$
\end{defn}
\begin{defn}
  ${p_n} \sim {q_n}$ if they have the same convergence (limits in both systems
  are equal).
\end{defn}
\begin{defn}
  $p_m in \{p_n\}$ --- \textbf{essential} if it can not be majorized by any of
  the preceeding halfnorms. $p_m$ can be majorized by $p_n$ if $\exists C, \forall x \in X
  p_n(x) \leq C \cdot p_m(x)$.
\end{defn}
\begin{stm}
  For any halfnorm system there exists equivalent monotonous system.
\end{stm}
\begin{proof}
  Let $q_n(x) = \sum\limits_{k = 1}^n p_k(x)$, it is obvious that every $q_n$ is
  halfnorm. ${q_n} \sim {p_n}?$
  $p_n(x_m - x) \to 0 \implies \sum\limits_{k = 1}^n p_k(x_m - x) \to 0 \implies
  q_n(x_m - x) \to 0$. Backwards proof is the same.
\end{proof}
This statement allows us to operate only on monotonous halfnorm systems.
\begin{stm}
  Two monotonous halfnorm systems are equivalent if and only if they majorize
  each other, i.e. for any halfnorm from first system there exists majorizing
  halfnorm from another and vice verca.
\end{stm}
\begin{proof}
  If two systems majorize each other obviously they are equivalent.
  Let two systems be equivalent. ${p_n}$ and ${q_n}$
\end{proof}
