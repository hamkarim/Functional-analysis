\section{Hilbert spaces}
\begin{defn}
  \textbf{Hilbert space} --- complete, infinite dimensional, inner product space.
\end{defn}

\begin{ex}
  $L_2(E)$ --- Hilbert space. \\
  $\inprod{f, g} = \int\limits_E f \cdot g\ d\mu$ \\
  $l_2 = \Set{(x_1, \dotsc, x_n, \dotsc) | \sum\limits_{n = 1}^\infty x_n^2 < +\infty}$ \\
  $\inprod{\bar{x}, \bar{y}} = \sum\limits_{n = 1}^\infty x_n y_n,\ E = \N,\ \mu\{m\} = 1$
\end{ex}

\noindent
When we have completeness we can define orthonormal basis.

\begin{defn}
  $H,\ \{e_n\}$ --- ONS $\colon \forall x = \sum\limits_{n = 1}^\infty \alpha_n e_n$
  Then $\{e_n\}$ is called \textbf{orthonormal basis}.\\
  Let's look at the inner product of arbitrary vector $x \in H$ and basis
  vector $e_m$ \\ 
  $\inprod{x, e_m} = \sum\limits_{n = 1}^\infty \alpha_n \inprod{e_n, e_m} =
  \alpha_m$ \\
  In this sense basis decomposition is always a Fourier series.
\end{defn}

\begin{enumerate}
\item Closed ONS\@: Let $L = \L\{e_1, e_2, \dots\}$, then $H = \cl{L}$ ($L$ is dense in $H$)
\item Complete ONS\@: $\forall m\ \inprod{x, e_m} = 0 \implies x = 0$.
\end{enumerate}

\begin{stm}
  \label{stm:ons_properties} In Hilbert spaces two of the properties outlined above are equivalent.
\end{stm}

\begin{stm}[Riesz-Fischer]
  In Hilbert space Fourier series converges for any point.
\end{stm}

\begin{proof}
  Let $H$ --- Hilbert space, $\sum\limits_{j = 1}^\infty \inprod{x, e_j}e_j$ --- abstract Fourier
  series, $S_n = \sum\limits_{j = 1}^n \inprod{x, e_j}e_j$ --- it's partial sum.
  We need to prove the existance of $\lim\limits_{n \to \infty} S_n$.
  $H$ is a Hilbert space, which means it is also complete. This means it is
  sufficient to prove that $\{S_n\}$ is a Cauchy sequence, i.e. 
  \[
    \forall \epsilon > 0\
    \exists N \in \N \colon \forall n, m > N\ \|S_n - S_m\| < \epsilon
  \]
  Consider 
  \[
    \|S_n - S_m\|^2 = \norm{\sum\limits_{j = 1}^n \inprod{x, e_j} e_j -
      \sum\limits_{j =  1}^m \inprod{x, e_j}e_j}^2 = \norm{\sum\limits_{j = m +
        1}^n \inprod{x, e_j}e_j}^2 = \sum\limits_{j = m + 1}^n \abs{\inprod{x,
        e_j}}^2
  \]
  Because numerical series $\sum\limits_{j = m + 1}^n \abs{\inprod{x, e_j}}^2$
  converges, by the Cauchy criteria we have the following: 
  \[
    \forall \epsilon > 0 \ \exists N \in \N\colon \forall n > m > N\ \abs{\sum\limits_{j = m + 1}^n
      \abs{\inprod{x, e_j}}^2} < \epsilon^2
  \]
  or 
  \[
    \sum\limits_{j = m + 1}^n \abs{\inprod{x, e_j}}^2 < \epsilon^2
  \]
  Which is essentially the same as:
  \[
    \|S_n - S_m\| < \epsilon.
  \]
\end{proof}

\begin{stm}[Parseval's identity]
  $x \in H = \sum \inprod{x, e_i}e_i$, then $\|x\|^2 = \sum |\inprod{x, e_i}|^2$
\end{stm}

\begin{proof}
  By inner product continuity
  \begin{align*}
    \|x\|^2 = \inprod{x, x} = \lim_n \inprod{S_n, S_n} &= \inprod{\sum_{i = 1}^n \inprod{x,
        e_i} e_i, \sum\limits_{j = 1}^n \inprod{x, e_j} e_j} = \\
    &= \lim_n \sum_{k = 1}^n |\inprod{x, e_k}|^2 = \sum^\infty |\inprod{x, e_i}|^2 \qedhere
  \end{align*}
\end{proof}

\begin{proof}
  \ref{stm:ons_properties}
  Closed ONS $\implies$ Complete ONS \\
  $\forall x \in H\ \forall \epsilon > 0\ \exists \sum\limits_{j =
    1}^p \alpha_{kj}e_{kj}\colon \underbrace{\|x - \sum\limits_{j = 1}^p
    \alpha_{kj}e_{kj}\|^2}_{\geq \|x - \sum\limits_{j = 1}^{k_p} \inprod{x, e_j} e_j\|^2}
  \leq \epsilon^2$ \\
  $S_m(x)$ by extremality $\|x - S_{m + p}(x)\|^2 \leq \|x - S_m(x)\|^2$ \\
  Implies partial sums go to x, $x = \sum\limits_{j = 1}^\infty \inprod{x, e_j} e_j$
  If all fourier coefficients are zero, it means the ONS is closed $(x = 0)$. \\
  Complete ONS $\implies$ Closed ONS \\
  Let $x \in H$, $y \coloneqq \sum\limits_{j = 1}^\infty \inprod{x, e_j}e_j$
  \begin{align*}
    \forall n\ \inprod{x - y, e_n} &= \inprod{x - \sum_{j = 1}^\infty \inprod{x, e_j} e_j, e_n} =
                                     \inprod{x, e_n} - \inprod{\sum_{j = 1}^\infty \inprod{x, e_j} e_j, e_n} =\\
                                   &= \inprod{x, e_n} - \sum_{j = 1}^\infty \inprod{x, e_j} \inprod{e_j, e_n} =
                                      \inprod{x, e_n} - \sum_{j = 1}^\infty \inprod{x, e_j} \delta_{j,n} = 0.
  \end{align*}
  Because ONS is complete $\inprod{x - y, e_n} = 0 \implies x - y = 0 \implies x =
  y$. Thus we can decompose any point into
  Fourier series, and this implies that ONS is closed.
\end{proof}

\begin{defn}
  Topological space is called \textbf{separable} if there exists countable dense set in it. \\
  $X = \cl{a_1, \dotsc, a_n, \dotsc}$
\end{defn}

\begin{note}
  If $H$ is separable, $\{a_1, \dotsc, a_n, \dotsc\}$ --- countable dense set in
  $H$. We can orthogonalize these dots using the Gramm-Shmidt process, and we
  will get complete orthonormal system. This means space separability is
  equivalent to basis existance.
\end{note}

\begin{thm}[about best approximation in Hilbert space]
  Let $H$ be Hilbert space, $M$ --- closed convex subset of $H$, then $\forall x \in H \ \exists!
  y \in M \colon \|x -y\| = \inf\limits_{z \in M}\|x - z\|$.
  In other words for any $x \in H$, the best approximation element exists, is
  contained in $M$ and is unique.
\end{thm}

\begin{proof}
  Let $d = \inf\limits_{z \in M}\|x - z\|$ \\
  Then by definition of infimum:
  \begin{align*}
    &\forall n \in \N \ \exists y_n \in M \colon d \leq \|x - y_n\| < d + \dfrac 1n \\
    &\exists ? y = \lim y_n \in M\ d \leq \|x - y\| \leq d 
  \end{align*}
  $y_n, y_m \in M$. $M$ is convex, which means
  \[
    \dfrac{y_n + y_m}{2} \in M \implies d^2
    \leq \norm{\dfrac{y_n + y_m}{2} - x}^2 = \dfrac{1}{4}\norm{\underbrace{(y_n - x)}_{z_1}
      + \underbrace{(y_m - x)}_{z_2}}^2 
  \]
  \\ Applying the parallelogram law, we get
  \begin{align*}
    &\|z_1 + z_2\|^2 + \|z_1 - z_2\|^2 = 2\|z_1\|^2 + 2\|z_2\|^2 \\
    &\underbrace{\|(y_n - x) + (y_m - x)\|^2}_{\geq 4d^2} + \|y_n -
      y_m\|^2 = 2\overbrace{\|y_n - x\|^2}^{\leq \left(d + \frac 1n\right)^2}
      + 2 \overbrace{\|y_m - x\|^2}^{\leq \left(d + \frac 1m\right)^2} \\
    &\|y_n - y_m\|^2 \leq 2(d + \dfrac 1n)^2 + 2(d + \dfrac 1m)^2 - 4d^2 = 4d \dfrac
      1n + \dfrac{2}{n^2} + 4 d \dfrac 1m + \dfrac{2}{m^2} \xrightarrow[n, m \to
      0]{} 0 \\
    &\|y_n - y_m\| \xrightarrow[n, m \to 0]{} 0 \implies \exists \lim y_n \qedhere
  \end{align*}
\end{proof}

\begin{cor}
  Let $H$ be Hilbert space, $H_1$ --- subspace of $H$ (closed linear subset). \\
  $H_2$ = $H_1^{\perp} = \Set{y \in H | y \perp x, x \in H_1}$ is called \textbf{orthogonal addition}. \\
  $\forall x \in H$ can be unambiguously written as $x = x_1 + x _2,\ x_1 \in H_1,\ x_2 \in H_1^{\perp}$
\end{cor}

\begin{note}
  $H = H_1 \oplus H_1^{\perp}$
\end{note}

\begin{proof}
  $x \in H,\ H_1,\ H_2 = H_1^{\perp}$
  \begin{align*}
    &\exists x_1 \in H_1 \colon \|x - x_1\| = \inf\limits_{n \in H_1}\|x - n\| \\
    &x_2 = x - x_1\ \in H_2 ? \\
    &\forall y \in H_1 y \perp x_2,\ \lambda > 0,\ x_ 1+ \lambda y \in H_1 (H_1 \text{--- subspace})
  \end{align*}
  \noindent
  By definition of best approximation element
  \[
    \|x - (x_1 + \lambda y)\|^2 \geq \|x - x_1\|^2 \ \forall \lambda > 0
  \]
  Let's expand squared norms via inner product. 
  \begin{align*}
    & \langle\underbrace{x - x_1}_{x_2} - \lambda y, x - x_1 - \lambda y\rangle \geq
      \inprod{x - x_1, x - x_1} \\
    &\inprod{x_2 - \lambda y, x_2 - \lambda y} \geq \inprod{x_2, x_2} \\
    &\inprod{x_2, x_2} - 2 \lambda \inprod{y, x_2} + \lambda^2 \inprod{y, y} \geq
      \inprod{x_2, x_2}\ : \lambda > 0 \\
    &2 \inprod{y, x_2} \leq \lambda \inprod{y, y},\ \lambda \to +0 \implies
      \inprod{y, x_2} \leq 0
  \end{align*}
  Then substitute $y$ for $-y$:
  \[
    \inprod{-y, x_2} \leq 0 \implies \inprod{y, x_2} \geq 0 \implies \inprod{y,
      x_2} = 0% \qedhere
  \]
\end{proof}
